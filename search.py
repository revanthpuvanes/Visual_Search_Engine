# -*- coding: utf-8 -*-
"""search.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pLGfKD0CvLILDuHWvCTeUv3LFnN8iNXb
"""

import tensorflow as tf
from tensorflow import keras
import numpy as np
#import pathlib
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from tensorflow.keras.models import Model
#from pathlib import Path
from PIL import Image
import matplotlib.pyplot as plt
#from tqdm import tqdm_notebook as tqdm
import pandas as pd
from keras.preprocessing.image import ImageDataGenerator, load_img
#import random
import os
#from google.colab import data_table

class FeatureExtractor:
    def __init__(self):
        # Use VGG-16 as the architecture and ImageNet for the weight
        base_model = VGG16(weights='imagenet')
        # Customize the model to return features from fully-connected layer
        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)
    def extract(self, img):
        #img = load_img(('\static\uploads,img_name), target_size=(224, 224))
        # Resize the image
        img = img.resize((224, 224))
        # Convert the image color space
        img = img.convert('RGB')
        # Reformat the image
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        # Extract Features
        feature = self.model.predict(x)[0]
        return feature / np.linalg.norm(feature)

fe = FeatureExtractor()

# def pre_process():
#   img = load_img((img_name), target_size=(224, 224))
#   return img

#img = pre_process()

#img = Image.open("E:\projects\image_search\upload")

#query = fe.extract(img)

#query

def feature_scores(query):
  features = pd.read_csv('./features/feature_extraction.csv')
  id = pd.read_csv('./features/product_id.csv')

  features_data = features.copy()
  features_data = features_data.drop(columns = ['image'])
  features_data = features_data.values
  dists = np.linalg.norm(features_data - query, axis=1)

# Extract images that have lowest distance
  ids = np.argsort(dists)[:5]
  lookalike_imgs = features.iloc[ids,:]['image']
  #product_id = id.iloc[ids,:]['id']
  scores = pd.DataFrame({'image': lookalike_imgs})
                        #'score': dists[ids]})
  scores = scores.reset_index(drop=True)
# Visualize the result
  #axes=[]
  #fig=plt.figure(figsize=(15,15))
  #for a in range(5):
      #score = scores['score'][a]
      #axes.append(fig.add_subplot(5, 1, a+1))
      #subplot_title=str(scores['image'][a])
      #axes[-1].set_title(subplot_title)  
      #plt.axis('off')
      #plt.imshow(Image.open('./static/images/' + scores['image'][a]))
  #fig.tight_layout()
  #plt.show()

  #result = scores['image'][a]
  return lookalike_imgs

#result = feature_scores()
def product_id(query):
  features = pd.read_csv('./features/feature_extraction.csv')
  id = pd.read_csv('./features/product_id.csv')

  features_data = features.copy()
  features_data = features_data.drop(columns = ['image'])
  features_data = features_data.values
  dists = np.linalg.norm(features_data - query, axis=1)

# Extract images that have lowest distance
  ids = np.argsort(dists)[:5]
  product_id = id.iloc[ids,:]['id']

  return product_id